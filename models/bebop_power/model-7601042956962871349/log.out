dataset path: /home/dharmesh/Documents/neurocontroller-hotm/datasets_and_models/bebop/dataset.npy
output indices: [6, 7]
learning rule: adam
learning rate: 0.001
minibatch size: 512
hid layer dims: [50, 50]

Train on 9440000 samples, validate on 1180000 samples
Epoch 1/500
 - 91s - loss: 0.0101 - mean_absolute_error: 0.0464 - val_loss: 0.0054 - val_mean_absolute_error: 0.0303
Epoch 2/500
 - 93s - loss: 0.0047 - mean_absolute_error: 0.0277 - val_loss: 0.0040 - val_mean_absolute_error: 0.0223
Epoch 3/500
 - 95s - loss: 0.0039 - mean_absolute_error: 0.0224 - val_loss: 0.0038 - val_mean_absolute_error: 0.0216
Epoch 4/500
 - 96s - loss: 0.0036 - mean_absolute_error: 0.0204 - val_loss: 0.0036 - val_mean_absolute_error: 0.0215
Epoch 5/500
 - 95s - loss: 0.0035 - mean_absolute_error: 0.0192 - val_loss: 0.0034 - val_mean_absolute_error: 0.0179
Epoch 6/500
 - 96s - loss: 0.0034 - mean_absolute_error: 0.0181 - val_loss: 0.0033 - val_mean_absolute_error: 0.0164
Epoch 7/500
 - 96s - loss: 0.0033 - mean_absolute_error: 0.0174 - val_loss: 0.0033 - val_mean_absolute_error: 0.0165
Epoch 8/500
 - 95s - loss: 0.0033 - mean_absolute_error: 0.0167 - val_loss: 0.0033 - val_mean_absolute_error: 0.0182
Epoch 9/500
 - 96s - loss: 0.0032 - mean_absolute_error: 0.0161 - val_loss: 0.0032 - val_mean_absolute_error: 0.0166

Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 10/500
 - 95s - loss: 0.0031 - mean_absolute_error: 0.0145 - val_loss: 0.0031 - val_mean_absolute_error: 0.0138
Epoch 11/500
 - 95s - loss: 0.0031 - mean_absolute_error: 0.0142 - val_loss: 0.0031 - val_mean_absolute_error: 0.0134
Epoch 12/500
 - 96s - loss: 0.0031 - mean_absolute_error: 0.0140 - val_loss: 0.0031 - val_mean_absolute_error: 0.0140
Epoch 13/500
 - 95s - loss: 0.0031 - mean_absolute_error: 0.0139 - val_loss: 0.0031 - val_mean_absolute_error: 0.0137
Epoch 14/500
 - 95s - loss: 0.0030 - mean_absolute_error: 0.0138 - val_loss: 0.0032 - val_mean_absolute_error: 0.0138

Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 15/500
 - 96s - loss: 0.0030 - mean_absolute_error: 0.0129 - val_loss: 0.0031 - val_mean_absolute_error: 0.0151
Epoch 16/500
 - 96s - loss: 0.0030 - mean_absolute_error: 0.0129 - val_loss: 0.0030 - val_mean_absolute_error: 0.0127
Epoch 17/500
 - 96s - loss: 0.0030 - mean_absolute_error: 0.0128 - val_loss: 0.0030 - val_mean_absolute_error: 0.0123
Epoch 18/500
 - 96s - loss: 0.0030 - mean_absolute_error: 0.0127 - val_loss: 0.0030 - val_mean_absolute_error: 0.0121
Epoch 19/500
 - 96s - loss: 0.0030 - mean_absolute_error: 0.0126 - val_loss: 0.0030 - val_mean_absolute_error: 0.0125
Epoch 20/500
 - 96s - loss: 0.0030 - mean_absolute_error: 0.0126 - val_loss: 0.0030 - val_mean_absolute_error: 0.0127
Epoch 21/500
 - 96s - loss: 0.0030 - mean_absolute_error: 0.0125 - val_loss: 0.0030 - val_mean_absolute_error: 0.0127

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 22/500
 - 96s - loss: 0.0029 - mean_absolute_error: 0.0120 - val_loss: 0.0030 - val_mean_absolute_error: 0.0119
Epoch 23/500
 - 96s - loss: 0.0029 - mean_absolute_error: 0.0120 - val_loss: 0.0030 - val_mean_absolute_error: 0.0116
Epoch 24/500
 - 96s - loss: 0.0029 - mean_absolute_error: 0.0120 - val_loss: 0.0030 - val_mean_absolute_error: 0.0122
Epoch 25/500
 - 96s - loss: 0.0029 - mean_absolute_error: 0.0119 - val_loss: 0.0030 - val_mean_absolute_error: 0.0118
Epoch 26/500
 - 95s - loss: 0.0029 - mean_absolute_error: 0.0119 - val_loss: 0.0030 - val_mean_absolute_error: 0.0117

Epoch 00026: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.
Epoch 27/500
 - 96s - loss: 0.0029 - mean_absolute_error: 0.0116 - val_loss: 0.0030 - val_mean_absolute_error: 0.0114
Epoch 28/500
 - 96s - loss: 0.0029 - mean_absolute_error: 0.0116 - val_loss: 0.0030 - val_mean_absolute_error: 0.0115
Epoch 29/500
 - 96s - loss: 0.0029 - mean_absolute_error: 0.0116 - val_loss: 0.0030 - val_mean_absolute_error: 0.0117
Epoch 30/500
 - 96s - loss: 0.0029 - mean_absolute_error: 0.0116 - val_loss: 0.0030 - val_mean_absolute_error: 0.0114
Epoch 31/500
 - 96s - loss: 0.0029 - mean_absolute_error: 0.0116 - val_loss: 0.0030 - val_mean_absolute_error: 0.0119
Epoch 32/500
 - 95s - loss: 0.0029 - mean_absolute_error: 0.0115 - val_loss: 0.0030 - val_mean_absolute_error: 0.0115
Epoch 33/500
 - 96s - loss: 0.0029 - mean_absolute_error: 0.0115 - val_loss: 0.0030 - val_mean_absolute_error: 0.0118

Epoch 00033: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.
Epoch 34/500
 - 96s - loss: 0.0029 - mean_absolute_error: 0.0114 - val_loss: 0.0029 - val_mean_absolute_error: 0.0113
Epoch 35/500
 - 96s - loss: 0.0029 - mean_absolute_error: 0.0114 - val_loss: 0.0029 - val_mean_absolute_error: 0.0113
Epoch 36/500
 - 96s - loss: 0.0029 - mean_absolute_error: 0.0114 - val_loss: 0.0029 - val_mean_absolute_error: 0.0113
Epoch 37/500
 - 96s - loss: 0.0029 - mean_absolute_error: 0.0114 - val_loss: 0.0029 - val_mean_absolute_error: 0.0116

Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.
Epoch 38/500
 - 96s - loss: 0.0029 - mean_absolute_error: 0.0113 - val_loss: 0.0029 - val_mean_absolute_error: 0.0113
Epoch 39/500
 - 95s - loss: 0.0029 - mean_absolute_error: 0.0113 - val_loss: 0.0029 - val_mean_absolute_error: 0.0113
Epoch 00039: early stopping
