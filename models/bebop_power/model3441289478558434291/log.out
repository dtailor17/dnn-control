dataset path: /home/dharmesh/Documents/neurocontroller-hotm/datasets_and_models/bebop/dataset.npy
output indices: [6, 7]
learning rule: adam
learning rate: 0.001
minibatch size: 512
hid layer dims: [100, 100, 100, 100, 100, 100, 100, 100, 100]

Train on 9440000 samples, validate on 1180000 samples
Epoch 1/500
 - 171s - loss: 0.0057 - mean_absolute_error: 0.0287 - val_loss: 0.0031 - val_mean_absolute_error: 0.0172
Epoch 2/500
 - 169s - loss: 0.0031 - mean_absolute_error: 0.0152 - val_loss: 0.0030 - val_mean_absolute_error: 0.0140
Epoch 3/500
 - 172s - loss: 0.0030 - mean_absolute_error: 0.0137 - val_loss: 0.0028 - val_mean_absolute_error: 0.0103
Epoch 4/500
 - 173s - loss: 0.0029 - mean_absolute_error: 0.0127 - val_loss: 0.0029 - val_mean_absolute_error: 0.0124
Epoch 5/500
 - 172s - loss: 0.0029 - mean_absolute_error: 0.0118 - val_loss: 0.0028 - val_mean_absolute_error: 0.0104
Epoch 6/500
 - 173s - loss: 0.0028 - mean_absolute_error: 0.0106 - val_loss: 0.0028 - val_mean_absolute_error: 0.0089
Epoch 7/500
 - 172s - loss: 0.0028 - mean_absolute_error: 0.0105 - val_loss: 0.0028 - val_mean_absolute_error: 0.0095
Epoch 8/500
 - 173s - loss: 0.0028 - mean_absolute_error: 0.0102 - val_loss: 0.0028 - val_mean_absolute_error: 0.0094
Epoch 9/500
 - 172s - loss: 0.0028 - mean_absolute_error: 0.0102 - val_loss: 0.0027 - val_mean_absolute_error: 0.0091

Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 10/500
 - 172s - loss: 0.0027 - mean_absolute_error: 0.0085 - val_loss: 0.0027 - val_mean_absolute_error: 0.0079
Epoch 11/500
 - 173s - loss: 0.0027 - mean_absolute_error: 0.0083 - val_loss: 0.0027 - val_mean_absolute_error: 0.0077
Epoch 12/500
 - 171s - loss: 0.0027 - mean_absolute_error: 0.0081 - val_loss: 0.0027 - val_mean_absolute_error: 0.0079
Epoch 13/500
 - 171s - loss: 0.0027 - mean_absolute_error: 0.0084 - val_loss: 0.0027 - val_mean_absolute_error: 0.0074
Epoch 14/500
 - 172s - loss: 0.0027 - mean_absolute_error: 0.0080 - val_loss: 0.0027 - val_mean_absolute_error: 0.0084
Epoch 15/500
 - 171s - loss: 0.0027 - mean_absolute_error: 0.0082 - val_loss: 0.0027 - val_mean_absolute_error: 0.0072
Epoch 16/500
 - 170s - loss: 0.0027 - mean_absolute_error: 0.0079 - val_loss: 0.0027 - val_mean_absolute_error: 0.0078
Epoch 17/500
 - 172s - loss: 0.0027 - mean_absolute_error: 0.0082 - val_loss: 0.0027 - val_mean_absolute_error: 0.0089
Epoch 18/500
 - 171s - loss: 0.0027 - mean_absolute_error: 0.0081 - val_loss: 0.0027 - val_mean_absolute_error: 0.0074

Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 19/500
 - 171s - loss: 0.0026 - mean_absolute_error: 0.0072 - val_loss: 0.0027 - val_mean_absolute_error: 0.0071
Epoch 20/500
 - 168s - loss: 0.0026 - mean_absolute_error: 0.0072 - val_loss: 0.0027 - val_mean_absolute_error: 0.0067
Epoch 21/500
 - 172s - loss: 0.0026 - mean_absolute_error: 0.0071 - val_loss: 0.0027 - val_mean_absolute_error: 0.0069
Epoch 22/500
 - 163s - loss: 0.0026 - mean_absolute_error: 0.0071 - val_loss: 0.0027 - val_mean_absolute_error: 0.0067
Epoch 23/500
 - 171s - loss: 0.0026 - mean_absolute_error: 0.0070 - val_loss: 0.0027 - val_mean_absolute_error: 0.0069

Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 24/500
 - 170s - loss: 0.0026 - mean_absolute_error: 0.0066 - val_loss: 0.0027 - val_mean_absolute_error: 0.0072
Epoch 25/500
 - 135s - loss: 0.0026 - mean_absolute_error: 0.0066 - val_loss: 0.0027 - val_mean_absolute_error: 0.0064
Epoch 26/500
 - 122s - loss: 0.0026 - mean_absolute_error: 0.0066 - val_loss: 0.0027 - val_mean_absolute_error: 0.0064
Epoch 27/500
 - 151s - loss: 0.0026 - mean_absolute_error: 0.0065 - val_loss: 0.0027 - val_mean_absolute_error: 0.0064
Epoch 28/500
 - 165s - loss: 0.0026 - mean_absolute_error: 0.0065 - val_loss: 0.0027 - val_mean_absolute_error: 0.0067
Epoch 29/500
 - 128s - loss: 0.0026 - mean_absolute_error: 0.0065 - val_loss: 0.0027 - val_mean_absolute_error: 0.0065

Epoch 00029: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.
Epoch 30/500
 - 123s - loss: 0.0026 - mean_absolute_error: 0.0063 - val_loss: 0.0027 - val_mean_absolute_error: 0.0063
Epoch 31/500
 - 152s - loss: 0.0026 - mean_absolute_error: 0.0063 - val_loss: 0.0027 - val_mean_absolute_error: 0.0067
Epoch 32/500
 - 160s - loss: 0.0026 - mean_absolute_error: 0.0063 - val_loss: 0.0027 - val_mean_absolute_error: 0.0063
Epoch 33/500
 - 164s - loss: 0.0026 - mean_absolute_error: 0.0063 - val_loss: 0.0027 - val_mean_absolute_error: 0.0064
Epoch 34/500
 - 166s - loss: 0.0026 - mean_absolute_error: 0.0062 - val_loss: 0.0027 - val_mean_absolute_error: 0.0061
Epoch 35/500
 - 164s - loss: 0.0026 - mean_absolute_error: 0.0062 - val_loss: 0.0027 - val_mean_absolute_error: 0.0062
Epoch 36/500
 - 158s - loss: 0.0026 - mean_absolute_error: 0.0062 - val_loss: 0.0027 - val_mean_absolute_error: 0.0063
Epoch 37/500
 - 160s - loss: 0.0026 - mean_absolute_error: 0.0062 - val_loss: 0.0027 - val_mean_absolute_error: 0.0065

Epoch 00037: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.
Epoch 38/500
 - 161s - loss: 0.0026 - mean_absolute_error: 0.0061 - val_loss: 0.0027 - val_mean_absolute_error: 0.0061
Epoch 39/500
 - 159s - loss: 0.0026 - mean_absolute_error: 0.0061 - val_loss: 0.0027 - val_mean_absolute_error: 0.0061
Epoch 40/500
 - 157s - loss: 0.0026 - mean_absolute_error: 0.0061 - val_loss: 0.0027 - val_mean_absolute_error: 0.0062
Epoch 41/500
 - 161s - loss: 0.0026 - mean_absolute_error: 0.0061 - val_loss: 0.0027 - val_mean_absolute_error: 0.0062

Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.
Epoch 42/500
 - 176s - loss: 0.0026 - mean_absolute_error: 0.0060 - val_loss: 0.0027 - val_mean_absolute_error: 0.0061
Epoch 43/500
 - 175s - loss: 0.0026 - mean_absolute_error: 0.0060 - val_loss: 0.0027 - val_mean_absolute_error: 0.0061
Epoch 44/500
 - 176s - loss: 0.0026 - mean_absolute_error: 0.0060 - val_loss: 0.0027 - val_mean_absolute_error: 0.0061
Epoch 45/500
 - 176s - loss: 0.0026 - mean_absolute_error: 0.0060 - val_loss: 0.0027 - val_mean_absolute_error: 0.0061
Epoch 46/500
 - 178s - loss: 0.0026 - mean_absolute_error: 0.0060 - val_loss: 0.0027 - val_mean_absolute_error: 0.0061
Epoch 47/500
 - 183s - loss: 0.0026 - mean_absolute_error: 0.0060 - val_loss: 0.0027 - val_mean_absolute_error: 0.0061
Epoch 48/500
 - 172s - loss: 0.0026 - mean_absolute_error: 0.0060 - val_loss: 0.0027 - val_mean_absolute_error: 0.0061

Epoch 00048: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.
Epoch 49/500
 - 170s - loss: 0.0026 - mean_absolute_error: 0.0060 - val_loss: 0.0027 - val_mean_absolute_error: 0.0060
Epoch 50/500
 - 170s - loss: 0.0026 - mean_absolute_error: 0.0060 - val_loss: 0.0027 - val_mean_absolute_error: 0.0060
Epoch 51/500
 - 172s - loss: 0.0026 - mean_absolute_error: 0.0060 - val_loss: 0.0027 - val_mean_absolute_error: 0.0060
Epoch 52/500
 - 172s - loss: 0.0026 - mean_absolute_error: 0.0060 - val_loss: 0.0027 - val_mean_absolute_error: 0.0060
Epoch 53/500
 - 173s - loss: 0.0026 - mean_absolute_error: 0.0059 - val_loss: 0.0027 - val_mean_absolute_error: 0.0060
Epoch 54/500
 - 172s - loss: 0.0026 - mean_absolute_error: 0.0059 - val_loss: 0.0027 - val_mean_absolute_error: 0.0060
Epoch 55/500
 - 171s - loss: 0.0026 - mean_absolute_error: 0.0059 - val_loss: 0.0027 - val_mean_absolute_error: 0.0060
Epoch 56/500
 - 172s - loss: 0.0026 - mean_absolute_error: 0.0059 - val_loss: 0.0027 - val_mean_absolute_error: 0.0060
Epoch 57/500
 - 172s - loss: 0.0026 - mean_absolute_error: 0.0059 - val_loss: 0.0027 - val_mean_absolute_error: 0.0060

Epoch 00057: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.
Epoch 58/500
 - 172s - loss: 0.0026 - mean_absolute_error: 0.0059 - val_loss: 0.0027 - val_mean_absolute_error: 0.0060
Epoch 59/500
 - 171s - loss: 0.0026 - mean_absolute_error: 0.0059 - val_loss: 0.0027 - val_mean_absolute_error: 0.0060
Epoch 60/500
 - 172s - loss: 0.0026 - mean_absolute_error: 0.0059 - val_loss: 0.0027 - val_mean_absolute_error: 0.0060
Epoch 61/500
 - 172s - loss: 0.0026 - mean_absolute_error: 0.0059 - val_loss: 0.0027 - val_mean_absolute_error: 0.0060
Epoch 62/500
 - 174s - loss: 0.0026 - mean_absolute_error: 0.0059 - val_loss: 0.0027 - val_mean_absolute_error: 0.0060
Epoch 63/500
 - 172s - loss: 0.0026 - mean_absolute_error: 0.0059 - val_loss: 0.0027 - val_mean_absolute_error: 0.0060
Epoch 64/500
 - 172s - loss: 0.0026 - mean_absolute_error: 0.0059 - val_loss: 0.0027 - val_mean_absolute_error: 0.0060
Epoch 65/500
 - 173s - loss: 0.0026 - mean_absolute_error: 0.0059 - val_loss: 0.0027 - val_mean_absolute_error: 0.0060

Epoch 00065: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.
Epoch 66/500
 - 173s - loss: 0.0026 - mean_absolute_error: 0.0059 - val_loss: 0.0027 - val_mean_absolute_error: 0.0060
Epoch 67/500
 - 174s - loss: 0.0026 - mean_absolute_error: 0.0059 - val_loss: 0.0027 - val_mean_absolute_error: 0.0060
Epoch 00067: early stopping
