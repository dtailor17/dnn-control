dataset path: /home/dharmesh/Documents/neurocontroller-hotm/datasets_and_models/bebop_time/dataset.npy
output indices: [6, 7]
learning rule: adam
learning rate: 0.001
minibatch size: 512
hid layer dims: [100, 100, 100]

Train on 9440000 samples, validate on 1180000 samples
Epoch 1/500
 - 126s - loss: 0.1022 - mean_absolute_error: 0.1137 - val_loss: 0.0462 - val_mean_absolute_error: 0.0625
Epoch 2/500
 - 111s - loss: 0.0384 - mean_absolute_error: 0.0500 - val_loss: 0.0282 - val_mean_absolute_error: 0.0399
Epoch 3/500
 - 111s - loss: 0.0285 - mean_absolute_error: 0.0391 - val_loss: 0.0263 - val_mean_absolute_error: 0.0407
Epoch 4/500
 - 112s - loss: 0.0249 - mean_absolute_error: 0.0351 - val_loss: 0.0209 - val_mean_absolute_error: 0.0312
Epoch 5/500
 - 111s - loss: 0.0230 - mean_absolute_error: 0.0328 - val_loss: 0.0230 - val_mean_absolute_error: 0.0310
Epoch 6/500
 - 111s - loss: 0.0219 - mean_absolute_error: 0.0315 - val_loss: 0.0230 - val_mean_absolute_error: 0.0320
Epoch 7/500
 - 111s - loss: 0.0210 - mean_absolute_error: 0.0306 - val_loss: 0.0183 - val_mean_absolute_error: 0.0317
Epoch 8/500
 - 111s - loss: 0.0204 - mean_absolute_error: 0.0300 - val_loss: 0.0241 - val_mean_absolute_error: 0.0401

Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 9/500
 - 111s - loss: 0.0174 - mean_absolute_error: 0.0272 - val_loss: 0.0188 - val_mean_absolute_error: 0.0282
Epoch 10/500
 - 111s - loss: 0.0170 - mean_absolute_error: 0.0268 - val_loss: 0.0170 - val_mean_absolute_error: 0.0260
Epoch 11/500
 - 111s - loss: 0.0168 - mean_absolute_error: 0.0265 - val_loss: 0.0175 - val_mean_absolute_error: 0.0249
Epoch 12/500
 - 111s - loss: 0.0166 - mean_absolute_error: 0.0262 - val_loss: 0.0167 - val_mean_absolute_error: 0.0253
Epoch 13/500
 - 111s - loss: 0.0164 - mean_absolute_error: 0.0260 - val_loss: 0.0168 - val_mean_absolute_error: 0.0249
Epoch 14/500
 - 111s - loss: 0.0162 - mean_absolute_error: 0.0258 - val_loss: 0.0172 - val_mean_absolute_error: 0.0252
Epoch 15/500
 - 111s - loss: 0.0161 - mean_absolute_error: 0.0256 - val_loss: 0.0157 - val_mean_absolute_error: 0.0249
Epoch 16/500
 - 111s - loss: 0.0159 - mean_absolute_error: 0.0255 - val_loss: 0.0158 - val_mean_absolute_error: 0.0250

Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 17/500
 - 111s - loss: 0.0147 - mean_absolute_error: 0.0241 - val_loss: 0.0148 - val_mean_absolute_error: 0.0247
Epoch 18/500
 - 111s - loss: 0.0146 - mean_absolute_error: 0.0241 - val_loss: 0.0147 - val_mean_absolute_error: 0.0233
Epoch 19/500
 - 111s - loss: 0.0145 - mean_absolute_error: 0.0240 - val_loss: 0.0146 - val_mean_absolute_error: 0.0243
Epoch 20/500
 - 111s - loss: 0.0145 - mean_absolute_error: 0.0239 - val_loss: 0.0148 - val_mean_absolute_error: 0.0244
Epoch 21/500
 - 112s - loss: 0.0144 - mean_absolute_error: 0.0238 - val_loss: 0.0143 - val_mean_absolute_error: 0.0246

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 22/500
 - 111s - loss: 0.0138 - mean_absolute_error: 0.0231 - val_loss: 0.0138 - val_mean_absolute_error: 0.0235
Epoch 23/500
 - 112s - loss: 0.0137 - mean_absolute_error: 0.0231 - val_loss: 0.0138 - val_mean_absolute_error: 0.0232
Epoch 24/500
 - 112s - loss: 0.0137 - mean_absolute_error: 0.0230 - val_loss: 0.0137 - val_mean_absolute_error: 0.0230
Epoch 25/500
 - 112s - loss: 0.0137 - mean_absolute_error: 0.0230 - val_loss: 0.0138 - val_mean_absolute_error: 0.0225
Epoch 26/500
 - 111s - loss: 0.0136 - mean_absolute_error: 0.0230 - val_loss: 0.0137 - val_mean_absolute_error: 0.0229
Epoch 27/500
 - 113s - loss: 0.0136 - mean_absolute_error: 0.0229 - val_loss: 0.0137 - val_mean_absolute_error: 0.0223
Epoch 28/500
 - 114s - loss: 0.0136 - mean_absolute_error: 0.0229 - val_loss: 0.0137 - val_mean_absolute_error: 0.0219
Epoch 29/500
 - 114s - loss: 0.0136 - mean_absolute_error: 0.0228 - val_loss: 0.0136 - val_mean_absolute_error: 0.0231
Epoch 30/500
 - 113s - loss: 0.0135 - mean_absolute_error: 0.0228 - val_loss: 0.0137 - val_mean_absolute_error: 0.0232
Epoch 31/500
 - 112s - loss: 0.0135 - mean_absolute_error: 0.0227 - val_loss: 0.0135 - val_mean_absolute_error: 0.0227

Epoch 00031: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.
Epoch 32/500
 - 113s - loss: 0.0132 - mean_absolute_error: 0.0224 - val_loss: 0.0134 - val_mean_absolute_error: 0.0223
Epoch 33/500
 - 114s - loss: 0.0132 - mean_absolute_error: 0.0224 - val_loss: 0.0133 - val_mean_absolute_error: 0.0225
Epoch 00033: early stopping
